{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Quotes\n",
      "0         Graphics designers are most creative people\n",
      "1   Artificial Intelligence or AI is the last inve...\n",
      "2   Snooker is a billiards sport for normally two ...\n",
      "3   Snooker is played on a large (12 feet by 6 fee...\n",
      "4    FOREX is the stock market for trading currencies\n",
      "5   Software Engineering is hotter and hotter topi...\n",
      "6                                       Love is blind\n",
      "7   Snooker is popular in the United Kingdom and m...\n",
      "8   The flying or operating of aircraft is known a...\n",
      "9   AI is likely to be either the best or worst th...\n",
      "10               Design is Intelligence made visible.\n",
      "11            Falling in love is like being on drugs.\n",
      "12  There is only one happiness in Life to Love an...\n",
      "13  Boeing 777 is considered world's largest econo...\n",
      "14  Warren Buffet is famous for making good invest...\n",
      "15  The biggest of the many uses of aviation are i...\n",
      "16  All giant majors in Silicon Valley is focusing...\n",
      "17  Investing in stocks and trading with them are ...\n",
      "18  Google will fulfill its mission only when its ...\n",
      "19  Being in love is the number one reason why peo...\n",
      "20  Aviation refers to flying using an aircraft li...\n",
      "21  Auomation is the biggest blessing given by Art...\n",
      "22  Graphics Designing is high rated freelance sub...\n",
      "23  Loving from a long distance actually strengthe...\n",
      "24             Real love is able to awaken your soul.\n",
      "25            Stuart Bingham is a champion of Snooker\n",
      "26  Software Engineer has average salary of $170K ...\n",
      "27  AI would have a low error rate compared to hum...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Graphics designers are most creative people',\n",
       " 'Artificial Intelligence or AI is the last invention - humans could ever make',\n",
       " 'Snooker is a billiards sport for normally two players.',\n",
       " 'Snooker is played on a large (12 feet by 6 feet) table that is covered with a smooth green material.',\n",
       " 'FOREX is the stock market for trading currencies',\n",
       " 'Software Engineering is hotter and hotter topic in Silicon Valley',\n",
       " 'Love is blind',\n",
       " 'Snooker is popular in the United Kingdom and many other countries',\n",
       " 'The flying or operating of aircraft is known as aviation.',\n",
       " 'AI is likely to be either the best or worst thing happen to humanity',\n",
       " 'Design is Intelligence made visible.',\n",
       " 'Falling in love is like being on drugs.',\n",
       " 'There is only one happiness in Life to Love and to be loved.',\n",
       " \"Boeing 777 is considered world's largest economical plane in the world of Aviation.\",\n",
       " 'Warren Buffet is famous for making good investments.He knows stock markets',\n",
       " 'The biggest of the many uses of aviation are in air travel and military aircraft.',\n",
       " 'All giant majors in Silicon Valley is focusing AI for their business productivity',\n",
       " 'Investing in stocks and trading with them are not that easy',\n",
       " \"Google will fulfill its mission only when its search engine is AI - complete You guys know what that means? That's Artificial Intelligence.\",\n",
       " 'Being in love is the number one reason why people wed.',\n",
       " 'Aviation refers to flying using an aircraft like an aeroplane.',\n",
       " 'Auomation is the biggest blessing given by Artificial Inteligence.',\n",
       " 'Graphics Designing is high rated freelance subject',\n",
       " 'Loving from a long distance actually strengthens a relationship',\n",
       " 'Real love is able to awaken your soul.',\n",
       " 'Stuart Bingham is a champion of Snooker',\n",
       " 'Software Engineer has average salary of $170K at Google',\n",
       " 'AI would have a low error rate compared to humans if coded properly. ']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#Collections is fetching dictionary of labels and clusters\n",
    "import collections\n",
    "#Natural Language ToolKit = nltk\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pprint import pprint\n",
    "\n",
    "#Reading dataset contains words and text\n",
    "dataset = pd.read_csv(\"E:\\\\ML Zero to Hero\\\\Quotes.csv\")\n",
    "print(dataset)\n",
    "\n",
    "#Converting data into list\n",
    "dataset_list = dataset[\"Quotes\"].tolist()\n",
    "dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function tokenizer for text\n",
    "def tokenizer(text):\n",
    "    \n",
    "    #tokenization is the process of splitting a large sample of text into words.\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(t) for t in tokens if t not in stopwords.words('english')]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster  0 :\n",
      "\n",
      "\t 1  :  Artificial Intelligence or AI is the last invention - humans could ever make\n",
      "\t 2  :  AI is likely to be either the best or worst thing happen to humanity\n",
      "\t 3  :  Google will fulfill its mission only when its search engine is AI - complete You guys know what that means? That's Artificial Intelligence.\n",
      "\t 4  :  Auomation is the biggest blessing given by Artificial Inteligence.\n",
      "\t 5  :  AI would have a low error rate compared to humans if coded properly. \n",
      "Cluster  1 :\n",
      "\n",
      "\t 1  :  Graphics designers are most creative people\n",
      "\t 2  :  Design is Intelligence made visible.\n",
      "\t 3  :  Being in love is the number one reason why people wed.\n",
      "\t 4  :  Graphics Designing is high rated freelance subject\n",
      "Cluster  2 :\n",
      "\n",
      "\t 1  :  Love is blind\n",
      "\t 2  :  Falling in love is like being on drugs.\n",
      "\t 3  :  There is only one happiness in Life to Love and to be loved.\n",
      "\t 4  :  Loving from a long distance actually strengthens a relationship\n",
      "\t 5  :  Real love is able to awaken your soul.\n",
      "Cluster  3 :\n",
      "\n",
      "\t 1  :  FOREX is the stock market for trading currencies\n",
      "\t 2  :  Warren Buffet is famous for making good investments.He knows stock markets\n",
      "\t 3  :  Investing in stocks and trading with them are not that easy\n",
      "Cluster  4 :\n",
      "\n",
      "\t 1  :  Snooker is a billiards sport for normally two players.\n",
      "\t 2  :  Snooker is played on a large (12 feet by 6 feet) table that is covered with a smooth green material.\n",
      "\t 3  :  Snooker is popular in the United Kingdom and many other countries\n",
      "\t 4  :  Stuart Bingham is a champion of Snooker\n",
      "Cluster  5 :\n",
      "\n",
      "\t 1  :  Software Engineering is hotter and hotter topic in Silicon Valley\n",
      "\t 2  :  All giant majors in Silicon Valley is focusing AI for their business productivity\n",
      "\t 3  :  Software Engineer has average salary of $170K at Google\n",
      "Cluster  6 :\n",
      "\n",
      "\t 1  :  The flying or operating of aircraft is known as aviation.\n",
      "\t 2  :  Boeing 777 is considered world's largest economical plane in the world of Aviation.\n",
      "\t 3  :  The biggest of the many uses of aviation are in air travel and military aircraft.\n",
      "\t 4  :  Aviation refers to flying using an aircraft like an aeroplane.\n"
     ]
    }
   ],
   "source": [
    "#---------------------Train our k-model and find tfidf Vectorizer matrix within same function--------------------------#\n",
    "\n",
    "def  cluster_sectences(dataset_list, k):\n",
    "    \n",
    "    #Creating tf ifd again:\n",
    "    #stopword ==== we filter out common words. for example (I, my, the, and etc....)\n",
    "    tfidf_vectorizer = TfidfVectorizer(tokenizer = tokenizer, stop_words = stopwords.words('english'), lowercase = True)\n",
    "    \n",
    "    #Build a tf-idf matrix for sentences\n",
    "    #Transform text to feature vectors that can be used as input to estimator\n",
    "    tdidf_matrix = tfidf_vectorizer.fit_transform(dataset_list)\n",
    "    \n",
    "    #Fitting k-means clustering\n",
    "    kmeans = KMeans(n_clusters = k)\n",
    "    kmeans.fit(tdidf_matrix)\n",
    "    \n",
    "    clusters = collections.defaultdict(list)\n",
    "    \n",
    "    for i, label in enumerate(kmeans.labels_):\n",
    "        clusters[label].append(i)\n",
    "        \n",
    "    \n",
    "    return dict(clusters)\n",
    "\n",
    "#Testing the model\n",
    "k = 7\n",
    "clusters = cluster_sectences(dataset_list, k)\n",
    "\n",
    "for cluster in range (k):\n",
    "    print(\"Cluster \", cluster, \":\\n\")\n",
    "    for i, sentence in enumerate(clusters[cluster]):\n",
    "        print(\"\\t\", (i + 1), \" : \", dataset_list[sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
